{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "WLVXy4ZWKyQJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsZPHAhmKv7L"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Datasets"
      ],
      "metadata": {
        "id": "eS1TmehOLjgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "def load_dataset(file_path):\n",
        "    return pd.read_excel(file_path)"
      ],
      "metadata": {
        "id": "AKNuwFWPLDNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess Text and Calculate Class Probabilities"
      ],
      "metadata": {
        "id": "tyJcRoXPLtKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_class_probabilities(data_frame):\n",
        "    total_data_points = len(data_frame)\n",
        "    class_probabilities = {}\n",
        "    word_counts_per_class = {}\n",
        "    all_words = set()\n",
        "\n",
        "    for index, row in data_frame.iterrows():\n",
        "        class_name = row['class']\n",
        "        words = row['words'].split()\n",
        "\n",
        "        if class_name not in word_counts_per_class:\n",
        "            word_counts_per_class[class_name] = {}\n",
        "\n",
        "        for word in words:\n",
        "            all_words.add(word)\n",
        "            word_counts_per_class[class_name][word] = word_counts_per_class[class_name].get(word, 0) + 1\n",
        "\n",
        "        class_probabilities[class_name] = class_probabilities.get(class_name, 0) + 1\n",
        "\n",
        "    for class_name in class_probabilities:\n",
        "        class_probabilities[class_name] /= total_data_points\n",
        "\n",
        "    total_unique_words = len(all_words)\n",
        "    return class_probabilities, word_counts_per_class, total_unique_words"
      ],
      "metadata": {
        "id": "D5j9-4lpMaqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate Conditional Probability of a word given a class"
      ],
      "metadata": {
        "id": "UcSKdPVAMhgz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_conditional_probability(word, class_name, word_counts_per_class, total_unique_words):\n",
        "    if word_counts_per_class.get(class_name) is None:\n",
        "        return 1 / total_unique_words\n",
        "\n",
        "    word_count_in_class = word_counts_per_class[class_name].get(word, 0)\n",
        "    total_words_in_class = sum(word_counts_per_class[class_name].values())\n",
        "    return (word_count_in_class + 1) / (total_words_in_class + total_unique_words)"
      ],
      "metadata": {
        "id": "6d8SNxahMong"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Find the most probable class for a sentence"
      ],
      "metadata": {
        "id": "-_o0KnmTMtGz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_most_probable_class(sentence, class_probabilities, word_counts_per_class, total_unique_words):\n",
        "    sentence_words = sentence.split()\n",
        "    class_probs = {}\n",
        "\n",
        "    for class_name in class_probabilities:\n",
        "        class_probability = class_probabilities[class_name]\n",
        "        word_probabilities = [get_conditional_probability(word, class_name, word_counts_per_class, total_unique_words) for word in sentence_words]\n",
        "        class_probs[class_name] = class_probability * np.prod(word_probabilities)\n",
        "\n",
        "    return max(class_probs, key=class_probs.get)\n"
      ],
      "metadata": {
        "id": "fdJbV77-MyDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take input & determine most probable class"
      ],
      "metadata": {
        "id": "gQMT7TB-M1zT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test sentence\n",
        "input_string = input(\"Enter a sentence: \")\n",
        "#example_input_string = \"Chinese Chinese Chinese Tokyo Japan\"\n",
        "# Load dataset\n",
        "dataset = load_dataset(\"/content/sample_data/dataset.xlsx\")\n",
        "\n",
        "# Preprocess data and calculate probabilities\n",
        "class_probabilities, word_counts_per_class, total_unique_words = calculate_class_probabilities(dataset)\n",
        "\n",
        "# Find most probable class\n",
        "most_probable_class = find_most_probable_class(input_string, class_probabilities, word_counts_per_class, total_unique_words)\n",
        "print(\"Most probable class for the input String:\", most_probable_class)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVjBFDg7OoFJ",
        "outputId": "905ae8b6-e92a-4e65-c87c-ae1e3072ad6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a sentence: Chinese Chinese Chinese Tokyo Japan\n",
            "Most probable class for the input String: c\n"
          ]
        }
      ]
    }
  ]
}